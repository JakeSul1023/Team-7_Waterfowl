# -*- coding: utf-8 -*-
"""Duck.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yxtzDArDUbhWMH1U0JgAnWbvhqOv8Nyp
"""

# -*- coding: utf-8 -*-
"""duck7_optimized.py

Optimized version that only calls weather data when making final predictions
"""

#Author: Revel Etheridge
#Date: 04-21-2025
#Model 4: Graph Neural Network (GNN) for Network-Based Migration Prediction
#Goal: Model migration as a graph problem using historical stopover sites.
#Why? Ducks tend to follow structured migration paths, which can be modeled as a graph of stopovers rather than just sequential time-series data.

#Approach:
#Nodes = Historical stopover locations.
#Edges = Migration connections between locations (weighted by frequency).
#GNN predicts the most probable next node (stopover location).
#Use Case: Useful for network-based decision-making, such as conservation planning.
#Assigned Team Members: Revel Etheridge, Kenny Adams

#Library declarations
import os
import pandas as pd
import matplotlib.pyplot as plt
import random
import networkx as nx
import numpy as np
import requests
from math import sqrt
from sklearn.cluster import DBSCAN
from datetime import datetime
import time

#Stored API Token
OPENWEATHER_API_KEY = "02de0c63b48bcd13d425a73caa22eb81"


#OpenWeather API integration functions
def get_openweather_forecast(lat, lon, api_key=OPENWEATHER_API_KEY):
    """
    Fetch weather data from OpenWeather API for a given latitude and longitude.
    Parameters:
    - lat: Latitude (rounded to 3 decimal places)
    - lon: Longitude (rounded to 3 decimal places)
    - api_key: OpenWeather API key
    Returns:
    - Dictionary containing weather data.
    """
    lat = round(lat, 3)
    lon = round(lon, 3)

    url = f"https://api.openweathermap.org/data/2.5/weather"
    params = {
        "lat": lat,
        "lon": lon,
        "appid": api_key,
        "units": "metric"  # Use "imperial" for Fahrenheit
    }
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        data = response.json()
        weather_info = {
            "latitude": lat,
            "longitude": lon,
            "temperature": data["main"]["temp"],
            "humidity": data["main"]["humidity"],
            "pressure": data["main"]["pressure"],
            "weather_description": data["weather"][0]["description"],
            "wind_speed": data["wind"]["speed"],
            "timestamp": pd.Timestamp.now()  # Adding timestamp for when data was collected
        }
        print(f"✅ Retrieved weather for ({lat}, {lon}): {weather_info['weather_description']}, {weather_info['temperature']}°C")
        return weather_info
    except requests.exceptions.RequestException as e:
        print(f"❌ Failed to retrieve weather for ({lat}, {lon}): {e}")
        return None


def fetch_openweather_forecast_for_points(lat_lon_list, api_key=OPENWEATHER_API_KEY):
    """
    Fetch weather forecasts for multiple latitude/longitude points.
    Parameters:
    - lat_lon_list: List of (latitude, longitude) tuples
    - api_key: OpenWeather API key
    Returns:
    - List of weather data dictionaries.
    """
    weather_data = []
    for lat, lon in lat_lon_list:
        weather_info = get_openweather_forecast(lat, lon, api_key)
        if weather_info:
            weather_data.append(weather_info)
        time.sleep(1.2)  # Adding a small delay to respect API rate limits
    return weather_data


def is_valid_openweather_point(lat, lon, api_key=OPENWEATHER_API_KEY):
    """
    Check if OpenWeather API can return valid data for a given lat/lon.
    Parameters:
    - lat: Latitude
    - lon: Longitude
    - api_key: OpenWeather API key
    Returns:
    - True if a valid forecast is found, False otherwise.
    """
    lat = round(lat, 3)
    lon = round(lon, 3)
    url = f"https://api.openweathermap.org/data/2.5/weather"
    params = {
        "lat": lat,
        "lon": lon,
        "appid": api_key
    }
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        return True
    except requests.exceptions.HTTPError:
        return False
    except Exception as e:
        print(f"Error checking OpenWeather point ({lat}, {lon}): {e}")
        return False


#Class Declaration - removed weather data methods from Duck class
class Duck():
    #Variable initializations
    def __init__(self, duckID):
        self.duckID = duckID
        self.species = ''
        self.longs = []
        self.lats = []
        self.coord = []
        self.timestamps = []

    def importLoc(self, df):
        #Saving duck ID's
        duck_data = df[df['tag-local-identifier'] == self.duckID]

        #Saving species
        self.species = duck_data['individual-taxon-canonical-name']

        #Saving timestamps
        self.timestamps = duck_data['timestamp'].tolist()

        #Saving longitudes
        self.long = duck_data['location-long'].tolist()

        #Saving latitudes
        self.lat = duck_data['location-lat'].tolist()

        #Combining coordinates
        self.coord = list(zip(self.long, self.lat))


#Function to print duck data for testing purposes
def print_duck_data(ducks_dict, label="Duck Data"):
    print(f"\n{label}:")
    print("-"*25)

    for duck_id, duck in ducks_dict.items():
        print(f"Duck ID: {duck_id}")
        print(f"  Timestamps: {duck.timestamps[:3]}{'...' if len(duck.timestamps) > 3 else ''}")

        #Print the first 3 coordinates
        print("  Coordinates (long, lat):")
        for i, (lng, lat) in enumerate(duck.coord[:3]):
            print(f"    {i+1}: ({lng}, {lat})")

        if len(duck.coord) > 3:
            print("    ...")

        #Print the total number of coordinates
        print(f"  Total locations: {len(duck.coord)}")
        print("-" * 30)


#Function to count the number of unique ducks present in the data set
def countDucks(df):
    #Pulling entire column of duck id's (including repeats)
    pooledIDs = df['tag-local-identifier'].tolist()

    #Placeholder for list of unique duck IDs
    uniqueIDs = list(set(pooledIDs))

    return len(uniqueIDs), uniqueIDs


#Function to allow developer to choose amount of ducks to choose from
def selectDucks(totalDucks, duckList):
    #Asking user for number of desired modeling units
    print("Total Number of unique duck IDs imported: ", totalDucks)
    portion = int(input("How many ducks would you like to model with? "))
    sampleIDs = random.sample(duckList, portion)

    return sampleIDs


#Function to create a node for each duck present in the data set
def create_nodes(ducks):
    nodes = set()
    for duck in ducks.values():
        nodes.update(duck.coord)
    return list(nodes)


#Function to normalize factor weights (edges can only hold values betwene 0 and 1)
def normalize_factor(val1, val2, threshhold=0.2):
    diff = abs(val1 - val2)

    if diff <= threshhold:
        return 1.0

    weight = np.exp(-diff)

    return max(0, min(1, weight))


#Calculate Haversine distance between two geographic coordinates
def haversine_distance(coord1, coord2):
    #Converting decimal degrees to radians
    lon1, lat1 = coord1
    lon2, lat2 = coord2
    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])

    #Haversine formula implementation
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    r = 6371  #Radius of earth in kilometers

    return c * r


#Create proximity-based graph preserving all original locations
def create_proximity_graph(ducks, proximity_threshold=0.5, sequential_weight=5.0):
    """
    Overall process - creates a graph that preserves all original locations and adds both:
    1. Sequential edges based on duck movements (heavily weighted)
    2. Proximity edges between nearby nodes (lighter weights)
    Arg specifications:
        proximity_threshold: Distance threshold in km to consider nodes as connected
        sequential_weight: Base weight for sequential edges (actual duck movements)
    """
    # Create graph
    G = nx.Graph()

    #Set all nodes while preserving all, full locations
    nodes = create_nodes(ducks)
    G.add_nodes_from(nodes)
    print(f"Added {len(nodes)} unique location nodes to graph")

    #Adding all sequential edges (actual duck movements)
    print("Adding sequential edges based on duck movements...")
    sequential_edges = []
    edge_count = {}
    duck_edge_map = {}

    for duck in ducks.values():
        for i in range(len(duck.coord) - 1):
            node1 = duck.coord[i]
            node2 = duck.coord[i + 1]

            #Skipping self-loops
            if node1 == node2:
                continue

            edge = (node1, node2)
            sequential_edges.append(edge)

            #Counting how many times each edge appears
            edge_count[edge] = edge_count.get(edge, 0) + 1

            #Storing which ducks used each edge
            if edge in duck_edge_map:
                duck_edge_map[edge].add(duck.duckID)
            else:
                duck_edge_map[edge] = {duck.duckID}

    #Adding sequential edges with weights based on frequency
    for edge, count in edge_count.items():
        weight = sequential_weight * count  #Note: Higher weight for frequently used paths
        G.add_edge(edge[0], edge[1], weight=weight, edge_type='sequential',
                   count=count, ducks=list(duck_edge_map[edge]))

    print(f"Added {len(edge_count)} sequential edges")

    #Adding proximity edges between nearby nodes that aren't already connected
    print("Adding proximity edges between nearby locations...")
    proximity_edges_added = 0

    #Checking nodes that are likely to be close (to maintain efficiency)
    #Grouping nodes into geographic bins
    bin_size = proximity_threshold * 2  #Note: km in longitude/latitude
    node_bins = {}

    for node in nodes:
        #Creating a bin key based on rough geographic location
        bin_x = int(node[0] / bin_size)
        bin_y = int(node[1] / bin_size)
        bin_key = (bin_x, bin_y)

        if bin_key in node_bins:
            node_bins[bin_key].append(node)
        else:
            node_bins[bin_key] = [node]

    #Checking proximity only for nodes in the same or adjacent bins
    for bin_key, bin_nodes in node_bins.items():
        bin_x, bin_y = bin_key

        #Getting nodes from current and adjacent bins
        nearby_nodes = bin_nodes.copy()
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                adj_key = (bin_x + dx, bin_y + dy)
                if adj_key in node_bins and adj_key != bin_key:
                    nearby_nodes.extend(node_bins[adj_key])

        #Checking proximity for nodes in this extended set
        for i, node1 in enumerate(bin_nodes):
            for node2 in nearby_nodes[i+1:]:  #Note: Starting from i+1 to avoid duplicate checks
                #Skipping if already connected by sequential edge
                if G.has_edge(node1, node2):
                    continue

                #Calculating distance
                distance = haversine_distance(node1, node2)

                #Connecting if within threshold
                if distance <= proximity_threshold:
                    #Weighting inversely proportional to distance (closer = stronger connection)
                    #Note: always less than sequential edges
                    weight = (1.0 - (distance / proximity_threshold)) * (sequential_weight * 0.5)
                    G.add_edge(node1, node2, weight=weight, edge_type='proximity',
                              distance=distance)
                    proximity_edges_added += 1

    print(f"Added {proximity_edges_added} proximity edges")
    print(f"Total graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges")

    return G, duck_edge_map


#Function to predict next location of duck - only fetch weather when actually predicting
def predict_next_location(G, current_location, weather_data=None, weather_weight=0.4,
                         prefer_sequential=True, temperature_range=(5, 25),
                         favorable_wind_speed=10, favorable_pressure_range=(1000, 1020)):
    """
    Predict next location considering both network structure and weather conditions.

    Args:
        G: NetworkX graph
        current_location: Current (lon, lat) tuple
        weather_data: Dictionary mapping locations to weather data
        weather_weight: How much to weigh weather vs. historical patterns (0-1)
        prefer_sequential: Whether to prioritize sequential edges
        temperature_range: Favorable temperature range (min, max) in Celsius
        favorable_wind_speed: Maximum favorable wind speed in m/s
        favorable_pressure_range: Favorable barometric pressure range (min, max) in hPa

    Returns:
        Next predicted location and prediction details
    """

    #Finding all neighboring nodes
    neighbors = list(G.neighbors(current_location))

    #Checking error case if node is completely isolated
    if not neighbors:
        print("No neighboring locations to predict next stopover.")
        return None, None

    #Variable initializations for comparison
    max_score = -1
    next_location = None
    prediction_details = {}

    #Cycling through all neighboring nodes to find best option
    for neighbor in neighbors:
        #Getting the base edge weight from the graph
        edge_weight = G[current_location][neighbor].get('weight', 1)

        #If prefer_sequential is True, prioritize sequential edges
        if prefer_sequential:
            edge_type = G[current_location][neighbor].get('edge_type', '')
            if edge_type == 'sequential':
                # Give sequential edges higher preference
                edge_weight = edge_weight * 2  # or some other boosting factor

        #Initializing composite score with historical weight
        historical_score = edge_weight
        weather_score = 1.0  # Default if no weather data

        #Calculating weather favorability if data is available
        weather_factors = {}
        if weather_data and neighbor in weather_data:
            neighbor_weather = weather_data[neighbor]

            #Temperature favorability (1.0 if in ideal range, decreasing as we move outside range)
            temp = neighbor_weather.get('temperature')
            if temp is not None:
                if temperature_range[0] <= temp <= temperature_range[1]:
                    temp_score = 1.0
                else:
                    #Decreasing score based on distance from range
                    dist_from_range = min(abs(temp - temperature_range[0]),
                                         abs(temp - temperature_range[1]))
                    temp_score = max(0.1, 1.0 - (dist_from_range / 10))
                weather_factors['temperature'] = temp_score
            else:
                temp_score = 0.5  # Neutral if no temperature data
                weather_factors['temperature'] = temp_score

            #Setting wind speed favorability (where lower wind speed is better for flying)
            wind = neighbor_weather.get('wind_speed')
            if wind is not None:
                wind_score = max(0.1, 1.0 - (wind / favorable_wind_speed))
                weather_factors['wind'] = wind_score
            else:
                wind_score = 0.5  #Setting neutral if no wind data
                weather_factors['wind'] = wind_score

            #Pressure favorability
            pressure = neighbor_weather.get('pressure')
            if pressure is not None:
                if favorable_pressure_range[0] <= pressure <= favorable_pressure_range[1]:
                    pressure_score = 1.0
                else:
                    #Decreasing score based on distance from range
                    dist_from_range = min(abs(pressure - favorable_pressure_range[0]),
                                         abs(pressure - favorable_pressure_range[1]))
                    pressure_score = max(0.1, 1.0 - (dist_from_range / 50))
                weather_factors['pressure'] = pressure_score
            else:
                pressure_score = 0.5  #Setting to neutral if no pressure data
                weather_factors['pressure'] = pressure_score

            #Combining weather factors
            weather_score = (temp_score + wind_score + pressure_score) / 3

        #Calculating final composite score
        #Note: historical_weight + weather_weight should equal 1
        historical_weight = 1 - weather_weight
        composite_score = (historical_weight * historical_score) + (weather_weight * weather_score)

        #Updating if this is the best score so far
        if composite_score > max_score:
            max_score = composite_score
            next_location = neighbor
            prediction_details = {
                'location': neighbor,
                'historical_score': historical_score,
                'weather_score': weather_score,
                'weather_factors': weather_factors,
                'composite_score': composite_score,
                'weather_data': weather_data.get(neighbor) if weather_data else None
            }

    #Returning edge with greatest likelihood and prediction details
    return next_location, prediction_details


#Visualizing the duck migration network
def visualize_migration_network(G, ducks, output_file="Spring_migration_network.png", highlight_duck_id=None):
    """
    Visualize the duck migration network with nodes colored by frequency
    and edges colored by type (sequential vs proximity)

    Args:
        G: NetworkX graph of the migration network
        ducks: Dictionary of Duck objects
        output_file: Where to save the visualization
        highlight_duck_id: Optional ID of a specific duck to highlight
    """
    plt.figure(figsize=(12, 10))

    #Calculating node sizes based on how many ducks visited each location
    node_visits = {node: 0 for node in G.nodes()}
    for duck in ducks.values():
        for coord in duck.coord:
            if coord in node_visits:
                node_visits[coord] += 1

    #Node colors based on frequency (heat map)
    node_colors = [np.log1p(node_visits[node]) for node in G.nodes()]

    #Edge colors based on type (sequential vs proximity)
    edge_colors = []
    for u, v, data in G.edges(data=True):
        if data.get('edge_type') == 'sequential':
            edge_colors.append('blue')
        else:
            edge_colors.append('gray')

    #Creating position map based on geographic coordinates
    pos = {node: (node[0], node[1]) for node in G.nodes()}

    #Drawing the network
    nx.draw_networkx_nodes(G, pos, node_color=node_colors,
                          node_size=[max(20, 5*visits) for visits in node_visits.values()],
                          cmap=plt.cm.YlOrRd, alpha=0.7)

    nx.draw_networkx_edges(G, pos, edge_color=edge_colors, width=0.5, alpha=0.6)

    #If highlighting a specific duck, draw its path
    if highlight_duck_id and highlight_duck_id in ducks:
        duck = ducks[highlight_duck_id]
        duck_path = []
        for i in range(len(duck.coord) - 1):
            duck_path.append((duck.coord[i], duck.coord[i+1]))

        nx.draw_networkx_edges(G, pos, edgelist=duck_path,
                              edge_color='red', width=2.0)

    plt.title("Duck Migration Network")
    plt.axis('off')
    plt.tight_layout()
    plt.savefig(output_file, dpi=300)
    plt.close()
    print(f"Network visualization saved to {output_file}")


def get_weather_for_prediction_locations(locations):
    """
    Fetch weather data for a set of locations.
    This is only called when making final predictions.

    Args:
        locations: List of (lon, lat) tuples

    Returns:
        Dictionary mapping locations to their weather data
    """
    # Format for API call: convert (lon, lat) to (lat, lon)
    weather_locations = [(loc[1], loc[0]) for loc in locations]

    # Fetch weather data
    print(f"Fetching weather data for {len(weather_locations)} locations...")
    weather_data_list = fetch_openweather_forecast_for_points(weather_locations)

    # Convert to dictionary for easy lookup
    weather_dict = {}
    for weather in weather_data_list:
        if weather:
            # Convert back to (lon, lat) format to match graph node keys
            location = (weather['longitude'], weather['latitude'])
            weather_dict[location] = weather

    return weather_dict


def predict_multiple_days(G, start_location, days=7, fetch_weather=True, weather_weight=0.4,
                         prefer_sequential=True, temperature_range=(5, 25),
                         favorable_wind_speed=10, favorable_pressure_range=(1000, 1020)):
    """
    Predict duck locations for multiple days ahead.
    Only fetches weather data if specifically requested.

    Args:
        G: NetworkX graph
        start_location: Starting (lon, lat) tuple
        days: Number of days to predict ahead
        fetch_weather: Whether to fetch real weather data (if False, uses historical patterns only)
        weather_weight: How much to weigh weather vs. historical patterns (0-1)
        prefer_sequential: Whether to prioritize sequential edges
        temperature_range: Favorable temperature range (min, max) in Celsius
        favorable_wind_speed: Maximum favorable wind speed in m/s
        favorable_pressure_range: Favorable barometric pressure range (min, max) in hPa

    Returns:
        List of predicted locations for each day and prediction details
    """
    predictions = []
    details = []
    current_location = start_location

    # If weather fetching is enabled, gather all potential locations first
    weather_data = None
    if fetch_weather:
        # Collect potential locations (limiting to 2-hop neighbors to reduce API calls)
        potential_locations = set()
        potential_locations.add(current_location)

        # First-hop neighbors
        for neighbor in G.neighbors(current_location):
            potential_locations.add(neighbor)

            # Second-hop neighbors (to reduce API calls, limit to sequential edges)
            for second_neighbor in G.neighbors(neighbor):
                if G[neighbor][second_neighbor].get('edge_type') == 'sequential':
                    potential_locations.add(second_neighbor)

        # Fetch weather only once for all potential locations
        weather_data = get_weather_for_prediction_locations(list(potential_locations))

    # Predict location for each day
    for day in range(1, days + 1):
        # Make prediction for this day
        next_location, prediction_detail = predict_next_location(
            G, current_location,
            weather_data=weather_data,
            weather_weight=weather_weight if fetch_weather else 0,  # If no weather data, rely only on historical
            prefer_sequential=prefer_sequential,
            temperature_range=temperature_range,
            favorable_wind_speed=favorable_wind_speed,
            favorable_pressure_range=favorable_pressure_range
        )

        # If no prediction could be made, use the last known location
        if not next_location:
            next_location = current_location
            prediction_detail = {
                'location': current_location,
                'note': 'No prediction available, using previous location'
            }

        predictions.append(next_location)
        details.append(prediction_detail)

        # Update current location for next day's prediction
        current_location = next_location

    return predictions, details


def export_predictions_to_csv(ducks, G, days=7, use_weather=True, weather_weight=0.4,
                             output_file="SpringDucks_P.csv"):
    """
    Generate predictions for all ducks across multiple days and export the results to a CSV file.
    Only fetches weather data once when making final predictions.
    Base timestamp is set to each duck's most recent data timestamp.

    Args:
        ducks: Dictionary of Duck objects
        G: NetworkX graph
        days: Number of days to predict ahead
        use_weather: Whether to use weather data in predictions
        weather_weight: Weight to give to weather factors in predictions
        output_file: Name of the CSV file to create
    """
    # Create a list to hold all prediction results
    prediction_results = []

    print(f"\nGenerating {days}-day predictions for {len(ducks)} ducks...")
    print(f"Weather data will{'' if use_weather else ' NOT'} be used in predictions")

    # For each duck
    for duck_id, duck in ducks.items():
        # Skip if no coordinates available
        if len(duck.coord) == 0:
            print(f"Skipping Duck {duck_id}: No location data available")
            continue

        # Get the duck's current location (most recent)
        current_location = duck.coord[-1]
        current_lon, current_lat = current_location

        # Use the duck's most recent timestamp as the base timestamp
        if duck.timestamps and len(duck.timestamps) > 0:
            # Get the most recent timestamp from the duck's data
            base_timestamp = pd.to_datetime(duck.timestamps[-1])
            base_timestamp_str = base_timestamp.strftime("%Y-%m-%d %H:%M:%S")
        else:
            # Fallback to current time if no timestamps available
            base_timestamp = datetime.now()
            base_timestamp_str = base_timestamp.strftime("%Y-%m-%d %H:%M:%S")
            print(f"Warning: No timestamps found for Duck {duck_id}, using current time as base")

        print(f"Predicting {days}-day trajectory for Duck {duck_id} from ({current_lat}, {current_lon})")

        # Make multi-day prediction (weather fetching happens inside this function now)
        predicted_locations, prediction_details = predict_multiple_days(
            G, current_location, days=days,
            fetch_weather=use_weather,
            weather_weight=weather_weight
        )

        # Create prediction records for each day
        for day, location in enumerate(predicted_locations, 1):
            # Calculate forecast timestamp by adding days to the base timestamp
            forecast_date = base_timestamp + pd.Timedelta(days=day)
            forecast_timestamp = forecast_date.strftime("%Y-%m-%d %H:%M:%S")

            # Extract coordinates
            forecast_lon, forecast_lat = location

            # Create prediction record
            prediction_data = {
                'duck_id': duck_id,
                'base_timestamp': base_timestamp_str,
                'forecast_day': day,
                'forecast_timestamp': forecast_timestamp,
                'start_lat': current_lat,
                'start_lon': current_lon,
                'forecast_lat': forecast_lat,
                'forecast_lon': forecast_lon
            }

            prediction_results.append(prediction_data)

        print(f"  Generated {days} daily predictions for Duck {duck_id}")

    # Convert to DataFrame
    predictions_df = pd.DataFrame(prediction_results)

    # Export to CSV
    predictions_df.to_csv(output_file, index=False)
    print(f"\nPrediction results exported to {output_file}")
    print(f"Total predictions: {len(prediction_results)} ({len(ducks)} ducks × {days} days)")

    if use_weather:
        print("Predictions incorporate real-time weather data")
    else:
        print("Predictions based on historical patterns only (no weather data used)")

    return predictions_df


def visualize_duck_trajectory(G, duck_id, predictions, output_file=None):
    """
    Visualize the predicted trajectory for a specific duck.

    Args:
        G: NetworkX graph
        duck_id: ID of the duck to visualize
        predictions: DataFrame containing predictions
        output_file: File to save the visualization (optional)
    """
    # Filter predictions for this duck
    duck_predictions = predictions[predictions['duck_id'] == duck_id]

    if duck_predictions.empty:
        print(f"No predictions available for Duck {duck_id}")
        return

    # Prepare plot
    plt.figure(figsize=(12, 10))

    # Create position map based on geographic coordinates
    pos = {node: (node[0], node[1]) for node in G.nodes()}

    # Draw the background network (light gray)
    nx.draw_networkx_nodes(G, pos, node_color='lightgray', node_size=5, alpha=0.3)
    nx.draw_networkx_edges(G, pos, edge_color='lightgray', width=0.2, alpha=0.2)

    # Get starting point
    start_lon = duck_predictions.iloc[0]['start_lon']
    start_lat = duck_predictions.iloc[0]['start_lat']
    start_point = (start_lon, start_lat)

    # Draw starting point (larger green node)
    nx.draw_networkx_nodes(G, pos, nodelist=[start_point],
                          node_color='green', node_size=300, alpha=0.8)

    # Collect trajectory points
    trajectory_points = [(row['forecast_lon'], row['forecast_lat'])
                         for _, row in duck_predictions.iterrows()]

    # Create trajectory edges
    trajectory_edges = [(start_point, trajectory_points[0])]
    trajectory_edges.extend([(trajectory_points[i], trajectory_points[i+1])
                             for i in range(len(trajectory_points)-1)])

    # Draw trajectory (thicker red line with arrows)
    nx.draw_networkx_edges(G, pos, edgelist=trajectory_edges,
                          edge_color='red', width=2.0, arrows=True)

    # Draw trajectory points with day numbers
    for day, point in enumerate(trajectory_points, 1):
        plt.text(point[0], point[1], str(day),
                fontsize=12, ha='center', va='center',
                bbox=dict(facecolor='white', alpha=0.7, edgecolor='black'))

    plt.title(f"{len(trajectory_points)}-Day Predicted Trajectory for Duck {duck_id}")
    plt.axis('off')

    # Save or show the plot
    if output_file:
        plt.savefig(output_file, dpi=300)
        plt.close()
        print(f"Trajectory visualization saved to {output_file}")
    else:
        plt.tight_layout()
        plt.show()


if __name__ == "__main__":
    # Reading in data set
    df = pd.read_csv("SpringData.csv")

    # Determining total number of ducks in sample
    total, uniqueIDs = countDucks(df)

    # Creating duck objects for each selected duck
    ducks = {}
    for duck_id in uniqueIDs:
        duck = Duck(duck_id)
        duck.importLoc(df)
        ducks[duck_id] = duck

    # Create migration network graph
    print("\nBuilding migration network graph...")
    G, duck_edge_map = create_proximity_graph(
        ducks,
        proximity_threshold=0.5,  # 0.5 km threshold for proximity connections
        sequential_weight=5.0     # Weight for sequential connections
    )

    # Visualize the overall migration network
    visualize_migration_network(G, ducks, "SpringDucks.png")

    # Generate predictions for all ducks (7-day forecast)
    predictions_df = export_predictions_to_csv(
        ducks,
        G,
        days=7,
        use_weather=True,  # Set to False to skip weather API calls
        weather_weight=0.4,
        output_file="SpringDucks_P.csv"
    )

    print("\nAnalysis complete!")